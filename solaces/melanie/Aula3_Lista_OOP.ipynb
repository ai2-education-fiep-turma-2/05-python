{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios Orientação a Objeto\n",
    "\n",
    "### Modele uma classe que realiza as seguintes operações em um arquivo texto\n",
    "\n",
    "* Represente um texto como uma lista de Strings\n",
    "* Retorne individualmente cada palavra do texto\n",
    "* Conte a quantidade de ocorrências de cada palavra do texto\n",
    "* Retorne as 10 palavras mais frequentes\n",
    "* Retorne a média e desvio padrão da quantidade de ocorrências\n",
    "* Cadastre StopWords (A classe deve possuir um atributo com uma lista de StopWords)\n",
    "* Retorne um novo arquivo eliminando todas as StopWords do texto\n",
    "* Inclua um método que retorne a distância entre duas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou contracted to thine own bright eyes,\n",
      "Feed'st thy light's flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thy self thy foe, to thy sweet self too cruel:\n",
      "Thou that art now the world's fresh ornament,\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content,\n",
      "And tender churl mak'st waste in niggarding:\n",
      "Pity the world, or else this glutton be,\n",
      "To eat the world's due, by the grave and thee.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import statistics\n",
    "\n",
    "class Texto:\n",
    "    \n",
    "    nome = 'ex1_OOP.txt'\n",
    "    words = 'words.txt'\n",
    "    caracteres = ',.:'\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Convertendo o arquivo para uma única string\n",
    "        self.__arquivo = open(Texto.nome, \"r\")\n",
    "        self.__unica_string = self.__arquivo.read()\n",
    "        self.__arquivo.close()\n",
    "    def lista_strings(self):\n",
    "        #Tirando os caracteres \",\" e \".\" da string\n",
    "        for caracter in Texto.caracteres:\n",
    "            self.__unica_string = self.__unica_string.replace(caracter, '')\n",
    "        #Represente um texto como uma lista de Strings\n",
    "        splited = self.__unica_string.split()\n",
    "        print(splited)\n",
    "        return(splited)\n",
    "    def palavra_individual(self):\n",
    "        #Retorne individualmente cada palavra do texto\n",
    "        splited = x.lista_strings()\n",
    "        for elemento in splited:\n",
    "            print(elemento)\n",
    "    def conta_ocorrencias(self):\n",
    "        #Conte a quantidade de ocorrências de cada palavra do texto\n",
    "        splited = x.lista_strings()\n",
    "        dicionario = dict()\n",
    "        \n",
    "        for palavra in splited:\n",
    "            if palavra in dicionario:\n",
    "                dicionario[palavra] += 1\n",
    "            else:\n",
    "                dicionario[palavra] = 1\n",
    "        print(f'Contagem de palavras: {dicionario}')\n",
    "        return(dicionario)\n",
    "    def palavras_frequentes(self):\n",
    "        #Retorne as 10 palavras mais frequentes\n",
    "        splited = x.lista_strings()\n",
    "        contadas = collections.Counter(splited)\n",
    "        mais_comuns = contadas.most_common(10)\n",
    "        return(mais_comuns)\n",
    "    def media_desvio(self):\n",
    "        #Retorne a média e desvio padrão da quantidade de ocorrências\n",
    "        dicionario = x.conta_ocorrencias()\n",
    "        lista_ocorrencias = list(dicionario.values())\n",
    "        media = statistics.mean(lista_ocorrencias)\n",
    "        desvio = statistics.pstdev(lista_ocorrencias)\n",
    "        resultado = {'Média': media ,'Desvio': desvio}\n",
    "        return(resultado)\n",
    "    def stop_words(self):\n",
    "        #Cadastre StopWords (A classe deve possuir um atributo com uma lista de StopWords)\n",
    "        #StopWords : são palavras que são consideradas irrelevantes para o conjunto de resultados \n",
    "        #a ser exibido em uma busca realizada em uma search engine. \n",
    "        #Exemplos: as, e, os, de, para, com, sem, foi.\n",
    "        \n",
    "        #Lendo o arquivo com as stop words em uma única string\n",
    "        arquivo = open(Texto.words, \"r\")\n",
    "        unica_string = arquivo.read()\n",
    "        arquivo.close()\n",
    "        #Convertendo a única string para uma lista de StopWords\n",
    "        stop_words = unica_string.split()\n",
    "        return(stop_words)\n",
    "    def elimina_stopwords(self):\n",
    "        #Retorne um novo arquivo eliminando todas as StopWords do texto\n",
    "        lista_texto_maiusculo = x.lista_strings()\n",
    "        lista_stopwords_maiusculo = x.stop_words()\n",
    "        #Convertendo todas as palavras a MINÚSCULO\n",
    "        lista_texto_minusculo = [x.lower() for x in lista_texto_maiusculo]\n",
    "        lista_stopwords_minusculo = [x.lower() for x in lista_stopwords_maiusculo]\n",
    "        for stop in lista_stopwords_minusculo:\n",
    "            for word in lista_texto_minusculo:\n",
    "                if word == stop:\n",
    "                    lista_texto_minusculo.remove(word)\n",
    "        return(lista_texto_minusculo)\n",
    "    def distancia(self, p1, p2):\n",
    "        #Inclua um método que retorne a distância entre duas palavras\n",
    "        #p1 = palabra 1 \n",
    "        #p2 = palabra 2\n",
    "        lista = x.lista_strings()\n",
    "        for palavra in lista:\n",
    "            if p1 == p2:\n",
    "                index1 = lista.index(p1)\n",
    "                lista_sliced = lista[index1+1:]\n",
    "                index2 = lista_sliced.index(p1) + (len(lista)-len(lista_sliced))\n",
    "            else:\n",
    "                if palavra == p1:\n",
    "                    index1 = lista.index(p1)\n",
    "                if palavra == p2:\n",
    "                    index2 = lista.index(p2)\n",
    "        \n",
    "        slice = lista[index1+1:index2]\n",
    "        print(f'Slice dos caracteres localiçados entre p1 e p2: {slice}')\n",
    "        caracteres = 1\n",
    "        for palavra in slice:\n",
    "            caracteres += len(palavra)+1\n",
    "        return(caracteres)\n",
    "                   \n",
    "x = Texto()\n",
    "print(x._Texto__unica_string)  #acessando mesmo sendo privado\n",
    "# x.lista_strings()\n",
    "# x.palavra_individual()\n",
    "# x.conta_ocorrencias()\n",
    "# x.palavras_frequentes()\n",
    "# x.media_desvio()\n",
    "# x.stop_words()\n",
    "# x.elimina_stopwords()\n",
    "# x.distancia('self','self')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
